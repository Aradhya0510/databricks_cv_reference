{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "\n",
    "This notebook demonstrates the deployment of computer vision models to production using Databricks Model Serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install dependencies\n",
    "!pip install databricks-sdk mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required modules\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from deployment.ci_cd.deployment_pipeline import DeploymentPipeline\n",
    "from deployment.serving.model_server import ModelServer\n",
    "import mlflow\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Deployment Pipeline\n",
    "\n",
    "Set up the deployment pipeline with necessary configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize workspace client\n",
    "workspace = WorkspaceClient(\n",
    "    host=\"https://your-workspace.cloud.databricks.com\",\n",
    "    token=\"your-token\"\n",
    ")\n",
    "\n",
    "# Initialize deployment pipeline\n",
    "pipeline = DeploymentPipeline(\n",
    "    workspace_url=\"https://your-workspace.cloud.databricks.com\",\n",
    "    token=\"your-token\",\n",
    "    model_name=\"cv_model\",\n",
    "    experiment_name=\"cv_experiment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Deployment Configuration\n",
    "\n",
    "Set up deployment parameters and thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define metrics threshold\n",
    "metrics_threshold = {\n",
    "    \"accuracy\": 0.9,\n",
    "    \"precision\": 0.9,\n",
    "    \"recall\": 0.9,\n",
    "    \"f1\": 0.9\n",
    "}\n",
    "\n",
    "# Define deployment configuration\n",
    "deployment_config = {\n",
    "    \"endpoint_name\": \"cv_model_endpoint\",\n",
    "    \"instance_type\": \"Standard_DS3_v2\",\n",
    "    \"min_instances\": 1,\n",
    "    \"max_instances\": 5,\n",
    "    \"scale_to_zero\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Deployment Pipeline\n",
    "\n",
    "Execute the deployment pipeline with the specified configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run deployment pipeline\n",
    "result = pipeline.run_pipeline(\n",
    "    metrics_threshold=metrics_threshold,\n",
    "    endpoint_name=deployment_config[\"endpoint_name\"]\n",
    ")\n",
    "\n",
    "print(\"Deployment completed!\")\n",
    "print(f\"Endpoint name: {result['endpoint_name']}\")\n",
    "print(f\"Model version: {result['model_version']}\")\n",
    "print(f\"Deployment time: {result['deployment_time']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model Server\n",
    "\n",
    "Set up the model server for monitoring and management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize model server\n",
    "server = ModelServer(\n",
    "    workspace_url=\"https://your-workspace.cloud.databricks.com\",\n",
    "    token=\"your-token\",\n",
    "    model_name=\"cv_model\",\n",
    "    model_version=result['model_version']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor Endpoint\n",
    "\n",
    "Set up monitoring for the deployed endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def monitor_endpoint(endpoint_name: str, duration: int = 300):\n",
    "    \"\"\"Monitor endpoint metrics for specified duration.\"\"\"\n",
    "    metrics_history = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while time.time() - start_time < duration:\n",
    "        metrics = server.monitor_endpoint(endpoint_name)\n",
    "        metrics_history.append(metrics)\n",
    "        time.sleep(10)  # Poll every 10 seconds\n",
    "    \n",
    "    return metrics_history\n",
    "\n",
    "# Start monitoring\n",
    "print(\"Starting endpoint monitoring...\")\n",
    "metrics_history = monitor_endpoint(result['endpoint_name'])\n",
    "\n",
    "# Plot metrics\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot([m['total_requests'] for m in metrics_history], label='Total Requests')\n",
    "plt.plot([m['average_latency'] for m in metrics_history], label='Average Latency')\n",
    "plt.plot([m['error_rate'] for m in metrics_history], label='Error Rate')\n",
    "plt.xlabel('Time (10s intervals)')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.title('Endpoint Metrics Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Endpoint\n",
    "\n",
    "Perform test inference on the deployed endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def test_endpoint(endpoint_name: str, test_data: list):\n",
    "    \"\"\"Test endpoint with sample data.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for data in test_data:\n",
    "        response = server.invoke_endpoint(endpoint_name, data)\n",
    "        results.append(response)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Load test data\n",
    "test_data = torch.load(\"/dbfs/path/to/test_data.pt\")\n",
    "test_samples = test_data[:5]  # Test with 5 samples\n",
    "\n",
    "# Run inference\n",
    "print(\"Running test inference...\")\n",
    "results = test_endpoint(result['endpoint_name'], test_samples)\n",
    "\n",
    "# Display results\n",
    "for i, (data, result) in enumerate(zip(test_samples, results)):\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"Input shape: {data.shape}\")\n",
    "    print(f\"Prediction: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "Clean up resources if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Delete endpoint if needed\n",
    "# server.delete_endpoint(result['endpoint_name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
} 