{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mco6R3f_OZwa"
      },
      "source": [
        "# Data Processing Pipeline\n",
        "\n",
        "This notebook demonstrates the data processing pipeline for computer vision tasks on Databricks.\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, let's install required dependencies and import necessary modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4Qw5xVROZwb"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "%pip install pycocotools albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwxERgBaOZwb"
      },
      "outputs": [],
      "source": [
        "# Import required modules\n",
        "from pyspark.sql import SparkSession\n",
        "import mlflow\n",
        "from data.unity_catalog.catalog_manager import CatalogManager\n",
        "import mlflow\n",
        "from data.processing.coco_processor import COCOProcessor\n",
        "from data.processing.data_loader import COCODataset, get_transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2yi_R5yOZwb"
      },
      "source": [
        "## Initialize Spark Session\n",
        "\n",
        "Create a Spark session for distributed data processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l16n6TosOZwb"
      },
      "outputs": [],
      "source": [
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"CV Data Processing\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get current user's email for catalog/schema naming\n",
        "current_user = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
        "user_prefix = current_user.split('@')[0]\n",
        "\n",
        "# Define catalog and schema names\n",
        "catalog_name = f\"{user_prefix}_cv_catalog\"\n",
        "schema_name = \"coco_dataset\"\n",
        "\n",
        "# Initialize catalog manager\n",
        "catalog_manager = CatalogManager(spark)\n",
        "\n",
        "# Create catalog if it doesn't exist\n",
        "catalog_manager.create_catalog_if_not_exists(\n",
        "    catalog_name=catalog_name,\n",
        "    comment=\"Catalog for computer vision datasets\"\n",
        ")\n",
        "\n",
        "# Create schema if it doesn't exist\n",
        "catalog_manager.create_schema_if_not_exists(\n",
        "    catalog_name=catalog_name,\n",
        "    schema_name=schema_name,\n",
        "    comment=\"Schema for COCO format datasets\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CYQ0fZ_OZwc"
      },
      "source": [
        "## Initialize COCO Processor\n",
        "\n",
        "Create a COCO processor instance to handle MS COCO format datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZOVWX46OZwc"
      },
      "outputs": [],
      "source": [
        "# Initialize processor with catalog manager\n",
        "processor = COCOProcessor(spark, catalog_manager=catalog_manager)\n",
        "\n",
        "# Load annotations\n",
        "annotation_file = \"/dbfs/path/to/annotations.json\"\n",
        "processor.load_coco_annotations(annotation_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amDXxSMCOZwc"
      },
      "source": [
        "## Process Images\n",
        "\n",
        "Process images and create a DataFrame with image metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "or7aFRasOZwc"
      },
      "outputs": [],
      "source": [
        "# Process images\n",
        "image_dir = \"/dbfs/path/to/images\"\n",
        "df = processor.process_images(image_dir)\n",
        "\n",
        "# Display sample data\n",
        "display(df.limit(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fefKMw5XOZwc"
      },
      "source": [
        "## Validate Data\n",
        "\n",
        "Perform data validation to ensure quality and consistency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBE9bCLcOZwc"
      },
      "outputs": [],
      "source": [
        "# Validate data\n",
        "validation_results = processor.validate_data(df)\n",
        "print(\"Validation results:\")\n",
        "for category, issues in validation_results.items():\n",
        "    print(f\"\\n{category}:\")\n",
        "    for issue in issues:\n",
        "        print(f\"- {issue}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxn5tHSkOZwc"
      },
      "source": [
        "## Create DataLoader\n",
        "\n",
        "Set up data loading for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPAuwoetOZwc"
      },
      "outputs": [],
      "source": [
        "# Create dataset\n",
        "dataset = COCODataset(\n",
        "    image_paths=df.select(\"image_path\").rdd.flatMap(lambda x: x).collect(),\n",
        "    annotations=df.select(\"annotations\").rdd.flatMap(lambda x: x).collect(),\n",
        "    transform=get_transforms(mode='train')\n",
        ")\n",
        "\n",
        "# Create dataloader\n",
        "dataloader = create_dataloader(\n",
        "    dataset,\n",
        "    batch_size=32,\n",
        "    num_workers=4,\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-68wv6XOZwc"
      },
      "source": [
        "## Save to Delta Lake\n",
        "\n",
        "Save processed data to Delta Lake format for efficient storage and querying."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kT5QPPOZOZwc"
      },
      "outputs": [],
      "source": [
        "# Save to Delta Lake with Unity Catalog\n",
        "processor.save_to_delta(\n",
        "    df=df,\n",
        "    catalog_name=catalog_name,\n",
        "    schema_name=schema_name,\n",
        "    table_name=\"coco_dataset\",\n",
        "    comment=\"Processed COCO dataset with annotations\"\n",
        ")\n",
        "\n",
        "# Verify saved data\n",
        "saved_df = spark.sql(f\"SELECT * FROM {catalog_name}.{schema_name}.coco_dataset\")\n",
        "print(f\"Total records: {saved_df.count()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKC-vMCjOZwc"
      },
      "source": [
        "## Visualize Sample Data\n",
        "\n",
        "Visualize sample images and annotations to verify data processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVORnxDjOZwc"
      },
      "outputs": [],
      "source": [
        "def visualize_sample(image, annotations):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    # Convert tensor to numpy array if needed\n",
        "    if torch.is_tensor(image):\n",
        "        image = image.permute(1, 2, 0).numpy()\n",
        "        # Denormalize if the image was normalized\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "    \n",
        "    plt.imshow(image)\n",
        "    \n",
        "    # Get boxes from annotations\n",
        "    boxes = annotations['boxes']\n",
        "    if torch.is_tensor(boxes):\n",
        "        boxes = boxes.numpy()\n",
        "    \n",
        "    for box in boxes:\n",
        "        x, y, w, h = box\n",
        "        rect = plt.Rectangle(\n",
        "            (x, y), w, h,\n",
        "            fill=False, edgecolor='red', linewidth=2\n",
        "        )\n",
        "        plt.gca().add_patch(rect)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Visualize a few samples\n",
        "for i in range(3):\n",
        "    image, annotations = dataset[i]\n",
        "    visualize_sample(image, annotations)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
